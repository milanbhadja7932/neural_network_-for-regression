{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "second_neural_network",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9-506--3F0A"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEHSpDA-7N2k"
      },
      "source": [
        "dataframe=pd.read_csv('/content/sample_data/dataset_housing.csv',delim_whitespace=True, header=None)\n",
        "dataset=dataframe.values\n",
        "X=dataset[:,0:13]\n",
        "y=dataset[:,13]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLenrion76I7"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(13,kernel_initializer='normal',activation='relu'))\n",
        "model.add(Dense(1,kernel_initializer='normal'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxr5RD69843-"
      },
      "source": [
        "model.compile(loss='mean_squared_error',optimizer='adam')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R5W0h7h9HoL",
        "outputId": "42d6c3d2-5313-4966-eda4-ab31a3cb5764"
      },
      "source": [
        "model.fit(X,y,epochs=150,batch_size=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "102/102 [==============================] - 1s 1ms/step - loss: 214.1818\n",
            "Epoch 2/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 82.1074\n",
            "Epoch 3/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 68.6584\n",
            "Epoch 4/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 63.9914\n",
            "Epoch 5/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 65.4667\n",
            "Epoch 6/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 52.0122\n",
            "Epoch 7/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 50.5152\n",
            "Epoch 8/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 48.5575\n",
            "Epoch 9/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 54.1538\n",
            "Epoch 10/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 45.5531\n",
            "Epoch 11/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 39.0524\n",
            "Epoch 12/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 48.2211\n",
            "Epoch 13/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 37.8066\n",
            "Epoch 14/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 41.2307\n",
            "Epoch 15/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 42.0888\n",
            "Epoch 16/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 40.4211\n",
            "Epoch 17/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31.6042\n",
            "Epoch 18/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 41.0104\n",
            "Epoch 19/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 40.1885\n",
            "Epoch 20/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35.3837\n",
            "Epoch 21/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 39.4518\n",
            "Epoch 22/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35.7639\n",
            "Epoch 23/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 37.2697\n",
            "Epoch 24/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32.4293\n",
            "Epoch 25/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 36.1015\n",
            "Epoch 26/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34.3365\n",
            "Epoch 27/150\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 33.6756\n",
            "Epoch 28/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33.5974\n",
            "Epoch 29/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.9285\n",
            "Epoch 30/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33.3615\n",
            "Epoch 31/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34.9555\n",
            "Epoch 32/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 28.8770\n",
            "Epoch 33/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.8048\n",
            "Epoch 34/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.2093\n",
            "Epoch 35/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.6212\n",
            "Epoch 36/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35.8460\n",
            "Epoch 37/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.5584\n",
            "Epoch 38/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35.8017\n",
            "Epoch 39/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32.5255\n",
            "Epoch 40/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 38.4320\n",
            "Epoch 41/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32.9943\n",
            "Epoch 42/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29.9595\n",
            "Epoch 43/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 28.9880\n",
            "Epoch 44/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33.8131\n",
            "Epoch 45/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.4759\n",
            "Epoch 46/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32.8640\n",
            "Epoch 47/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29.4875\n",
            "Epoch 48/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31.2347\n",
            "Epoch 49/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 36.7791\n",
            "Epoch 50/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32.0830\n",
            "Epoch 51/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 32.6289\n",
            "Epoch 52/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 33.2921\n",
            "Epoch 53/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.1545\n",
            "Epoch 54/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 35.8733\n",
            "Epoch 55/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 28.3840\n",
            "Epoch 56/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.8310\n",
            "Epoch 57/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 28.7876\n",
            "Epoch 58/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.1600\n",
            "Epoch 59/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 27.6316\n",
            "Epoch 60/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29.8234\n",
            "Epoch 61/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 27.6993\n",
            "Epoch 62/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 34.9759\n",
            "Epoch 63/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29.9339\n",
            "Epoch 64/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.9502\n",
            "Epoch 65/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 25.6214\n",
            "Epoch 66/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 22.6269\n",
            "Epoch 67/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 28.1106\n",
            "Epoch 68/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 25.1628\n",
            "Epoch 69/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.1806\n",
            "Epoch 70/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 25.1317\n",
            "Epoch 71/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29.3753\n",
            "Epoch 72/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 26.2941\n",
            "Epoch 73/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 29.1594\n",
            "Epoch 74/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 26.4645\n",
            "Epoch 75/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.9128\n",
            "Epoch 76/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 27.3809\n",
            "Epoch 77/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 30.9944\n",
            "Epoch 78/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 28.7956\n",
            "Epoch 79/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.2187\n",
            "Epoch 80/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 31.0177\n",
            "Epoch 81/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 26.6300\n",
            "Epoch 82/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 28.7630\n",
            "Epoch 83/150\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 23.0123\n",
            "Epoch 84/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 25.7118\n",
            "Epoch 85/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.7420\n",
            "Epoch 86/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.5197\n",
            "Epoch 87/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.8216\n",
            "Epoch 88/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 26.3827\n",
            "Epoch 89/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.8407\n",
            "Epoch 90/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.1129\n",
            "Epoch 91/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.3588\n",
            "Epoch 92/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 25.3471\n",
            "Epoch 93/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.8381\n",
            "Epoch 94/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.0190\n",
            "Epoch 95/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.5875\n",
            "Epoch 96/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 27.8789\n",
            "Epoch 97/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 25.8412\n",
            "Epoch 98/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.0619\n",
            "Epoch 99/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.7793\n",
            "Epoch 100/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 22.8579\n",
            "Epoch 101/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.0637\n",
            "Epoch 102/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 19.4154\n",
            "Epoch 103/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.1913\n",
            "Epoch 104/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.8504\n",
            "Epoch 105/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 22.7961\n",
            "Epoch 106/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 24.4689\n",
            "Epoch 107/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.8210\n",
            "Epoch 108/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 27.5508\n",
            "Epoch 109/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.9401\n",
            "Epoch 110/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 21.1907\n",
            "Epoch 111/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.8838\n",
            "Epoch 112/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.1710\n",
            "Epoch 113/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.2222\n",
            "Epoch 114/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.1950\n",
            "Epoch 115/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.0013\n",
            "Epoch 116/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.5073\n",
            "Epoch 117/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.2970\n",
            "Epoch 118/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 16.0691\n",
            "Epoch 119/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 19.7490\n",
            "Epoch 120/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.1560\n",
            "Epoch 121/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.1141\n",
            "Epoch 122/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 17.7134\n",
            "Epoch 123/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 16.6497\n",
            "Epoch 124/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.9702\n",
            "Epoch 125/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 19.0541\n",
            "Epoch 126/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 23.6394\n",
            "Epoch 127/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.5209\n",
            "Epoch 128/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 19.1298\n",
            "Epoch 129/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.8398\n",
            "Epoch 130/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 21.6720\n",
            "Epoch 131/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 22.2183\n",
            "Epoch 132/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 21.7934\n",
            "Epoch 133/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 16.8839\n",
            "Epoch 134/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.9755\n",
            "Epoch 135/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 15.6488\n",
            "Epoch 136/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 19.0262\n",
            "Epoch 137/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 21.2341\n",
            "Epoch 138/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 17.5031\n",
            "Epoch 139/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.0060\n",
            "Epoch 140/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 17.2968\n",
            "Epoch 141/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 16.3963\n",
            "Epoch 142/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 15.8244\n",
            "Epoch 143/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 22.2902\n",
            "Epoch 144/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 15.3337\n",
            "Epoch 145/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.8871\n",
            "Epoch 146/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 16.5112\n",
            "Epoch 147/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 17.5101\n",
            "Epoch 148/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 20.2322\n",
            "Epoch 149/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 16.2678\n",
            "Epoch 150/150\n",
            "102/102 [==============================] - 0s 1ms/step - loss: 18.1560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f999b72db50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8nGQhTP9zYE",
        "outputId": "3626497f-1569-4413-da69-ba78d512fe53"
      },
      "source": [
        "predictions=model.predict_classes(X)\n",
        "for i in range(15):\n",
        "  print(predictions[i],y[i])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] 24.0\n",
            "[1] 21.6\n",
            "[1] 34.7\n",
            "[1] 33.4\n",
            "[1] 36.2\n",
            "[1] 28.7\n",
            "[1] 22.9\n",
            "[1] 27.1\n",
            "[1] 16.5\n",
            "[1] 18.9\n",
            "[1] 15.0\n",
            "[1] 18.9\n",
            "[1] 21.7\n",
            "[1] 20.4\n",
            "[1] 18.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rxFjJ6_-Sfr",
        "outputId": "e4baff03-f27b-4099-e195-4dc42e4ea5c6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 196\n",
            "Trainable params: 196\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs5bMz_c-U6D"
      },
      "source": [
        "**Improve the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ueJYjr-Yzr"
      },
      "source": [
        "def baseline_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal'))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCr9SV7X-Y2h",
        "outputId": "04de66cf-4c0e-489c-9e22-27ae7a398714"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "estimator=KerasRegressor(build_fn=baseline_model,epochs=100, batch_size=5, verbose=1)\n",
        "kfold=KFold(n_splits=10)\n",
        "results = cross_val_score(estimator, X, y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-28.052433013916016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72ZyxUqB-Y4_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_-6IWNM-Y8E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}